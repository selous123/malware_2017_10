from __future__ import division
from config import DefaultConfig
from models.BasicModel import Net
from data.dataset import malwareDataset,malwareData
import numpy as np
import torch
from tabulate import tabulate

conf = DefaultConfig()

def loss(logits,labels,*args):
    """
    Args:
        logits: prediction of samples,[batch_size,1]
        labels: true label of samples,[batch_size,1]
    Return:
        cross entropy loss,[1,]
    """
    if args:
        loss = -torch.sum((labels*torch.log(logits)+(1-labels)*torch.log(1-logits))*args[0])/torch.sum(args[0])
    else:
        loss = -torch.mean(labels*torch.log(logits)+(1-labels)*torch.log(1-logits))
    assert loss.size()==(1,) 
    return loss
    """
    loss = labels*torch.log(logits)+(1-labels)*torch.log(1-logits)
    v = loss.le(1/conf.K)
    loss = -torch.mean(loss[v])
    """

def computeV(labels,logits):
    
    loss = -(labels*torch.log(logits)+(1-labels)*torch.log(1-logits))
    #if loss<1/K : v = 1"easy sample"
    v1 = torch.le(loss,1/conf.K).type(torch.DoubleTensor)
    #print "v1:"
    #print v1.view(16,32)
    #print "labels:"
    #print labels.view(16,32)
    v2 = (labels==1).type(torch.DoubleTensor)
    #print type(labels)
    v = v1+v2-v1*v2
    #print v.view(64,8)
    return v

import torch.optim as optim
from torch.autograd import Variable
def train(net):
    ###read file
    if conf.read_all_data:
        train_dataset = malwareData(conf.root_path,train=True)
    else:
        train_dataset = malwareDataset(conf.root_path,train=True)
    dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=conf.batch_size,shuffle=True,drop_last=True)
    #dataiter = iter(dataloader)
    
    ###optimizer
    optimize = optim.SGD(net.parameters(),lr = conf.lr)
    
    for epoch in range(conf.epoch_num):
        #each epoch loss
        #print "epoch:{}".format(epoch)
        running_loss = []
        for i,data in enumerate(dataloader,0):
            images,labels = data
            images,labels = images.type(torch.DoubleTensor),labels.type(torch.DoubleTensor)
            if conf.cuda:
                images,labels = images.cuda(),labels.cuda()
            #print type(images)
            images,labels = Variable(images),Variable(labels)
            #print images[1]
            #print labels.data.numpy()
            #raw_input("wait")
            logits = net(images)
            print logits.data.view(64,8)
            #choose "easy" sample
            if conf.spl: 
                v = computeV(labels,logits)
                if v.type(torch.ByteTensor).any()==0:
                    print "what the fuck"
                    continue
                if conf.cuda:
                    v = v.cuda()
                #print logits.data.numpy()
                l = loss(logits,labels,v)
            else:
                l = loss(logits,labels)
            running_loss.append(l.data.cpu().numpy()[0])
            optimize.zero_grad()
            l.backward()
            optimize.step()
            print "epoch is:{},step is:{},loss is:{}".format(epoch,i,l.data[0])
	#print running_loss
        if conf.spl and running_loss!=0 and sum(running_loss)/len(running_loss) < conf.update_threshold:
            conf.K = conf.K/2
            print "update age K to {}".format(conf.K)
        print "epoch is:{},loss is:{}".format(epoch,l.data[0])

def val(net):
    pass

def test(net):
    #load data
    if conf.read_all_data:
        test_dataset= malwareData(conf.root_path,train=False)
    else:
        test_dataset = malwareDataset(conf.root_path,train=False)
    data_loader = torch.utils.data.DataLoader(test_dataset,batch_size=512,shuffle=False,drop_last=False)
    
    true_positive_num = 0
    predicted_positive_num = 0
    predicted_true_positive_num = 0
    predicted_false_negative_num = 0
    for images,labels in data_loader:
        #move the images to GPU
        images = images.type(torch.DoubleTensor)
        if conf.cuda:
            images = images.cuda()
        logits = net(Variable(images))
        ##greater and equal
        #print logits
        predicted = logits.data.ge(0.5)
        if conf.cuda:
            predicted = predicted.cpu()
        
        predicted = predicted.numpy() 
        #print predicted
        labels = labels.numpy()
        true_positive_num += np.sum(labels == 1)
        predicted_positive_num += np.sum(predicted == 1)
        predicted_true_positive_num += np.sum((labels==1)&(predicted==1))
        predicted_false_negative_num += np.sum((labels==0)&(predicted==0))
# =============================================================================
#         print predicted.size()
#         print labels.squeeze().size()
#         raw_input("wait")
#
#        #labels = labels.type('torch.ByteTensor')
#        total += labels.size(0)
#        correct += (predicted.cpu().numpy() == labels.numpy()).sum()
# =============================================================================
    
    confusion_matrix = [["table","predicted malware(1)","predicted normal(0)"],
                         ["actual malware(1)",predicted_true_positive_num,true_positive_num-predicted_true_positive_num],
                         ["actual normal(0)",predicted_positive_num-predicted_true_positive_num,predicted_false_negative_num]]
    print tabulate(confusion_matrix)    
    print "Precision is {},Recall is {}".format(predicted_true_positive_num/predicted_positive_num,predicted_true_positive_num/true_positive_num)
if __name__=='__main__':
    
    
    net = Net()
    if conf.cuda:
        net.cuda()
    net.double()
    if conf.istraining:
        train(net)
        torch.save(net.state_dict(),conf.pkl_name)
    else:
        net.load_state_dict(torch.load(conf.pkl_name,map_location=lambda storage, loc: storage))
        test(net)
    #print "learning rate is {}".format(conf.lr)
